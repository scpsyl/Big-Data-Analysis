{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import coo_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据导入\n",
    "train_data = pd.read_csv('data/netflix_train.txt', sep=r'\\s+', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "test_data = pd.read_csv('data/netflix_test.txt', sep=r'\\s+', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "all_users = pd.concat([train_data['user_id'], test_data['user_id']]).unique()\n",
    "all_movies = pd.concat([train_data['movie_id'], test_data['movie_id']]).unique()\n",
    "\n",
    "user_id_to_index = {user_id: idx for idx, user_id in enumerate(all_users)}\n",
    "movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(all_movies)}\n",
    "\n",
    "num_users = len(all_users)\n",
    "print(num_users) #10000\n",
    "num_movies = len(all_movies)\n",
    "print(num_movies) #10000\n",
    "\n",
    "train_data['user_idx'] = train_data['user_id'].map(user_id_to_index)\n",
    "train_data['movie_idx'] = train_data['movie_id'].map(movie_id_to_index)\n",
    "test_data['user_idx'] = test_data['user_id'].map(user_id_to_index)\n",
    "test_data['movie_idx'] = test_data['movie_id'].map(movie_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建稀疏矩阵\n",
    "train_ratings = coo_matrix(\n",
    "    (train_data['rating'], (train_data['user_idx'], train_data['movie_idx'])),\n",
    "    shape=(num_users, num_movies)\n",
    ")\n",
    "test_ratings = coo_matrix(\n",
    "    (test_data['rating'], (test_data['user_idx'], test_data['movie_idx'])),\n",
    "    shape=(num_users, num_movies)\n",
    ")\n",
    "\n",
    "# 使用 Torch 创建稠密矩阵 GPU加速计算\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #cuda\n",
    "train_ratings_tensor = torch.FloatTensor(train_ratings.toarray()).to(device)\n",
    "test_ratings_tensor = torch.FloatTensor(test_ratings.toarray()).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 协同过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算用户相似度\n",
    "def compute_user_similarity(ratings):\n",
    "    user_norms = torch.norm(ratings, dim=1).unsqueeze(1)\n",
    "    user_norms[user_norms == 0] = 1e-10\n",
    "    normalized_ratings = ratings / user_norms\n",
    "    similarity = torch.matmul(normalized_ratings, normalized_ratings.T)\n",
    "    return similarity\n",
    "\n",
    "# 预测评分\n",
    "def predict(ratings, similarity, k=50):\n",
    "    _, top_k_users = torch.topk(similarity, k=k, dim=1)\n",
    "    pred_ratings = torch.zeros_like(ratings)\n",
    "    num_users = ratings.shape[0]\n",
    "    for i in range(num_users):\n",
    "        neighbors = top_k_users[i]\n",
    "        sim_scores = similarity[i][neighbors]\n",
    "        neighbor_ratings = ratings[neighbors]\n",
    "        sim_scores_expanded = sim_scores.unsqueeze(1)\n",
    "        numerator = torch.sum(neighbor_ratings * sim_scores_expanded, dim=0)\n",
    "        denominator = torch.sum((neighbor_ratings != 0).float() * sim_scores_expanded, dim=0)\n",
    "        denominator[denominator == 0] = 1e-10\n",
    "        pred_ratings[i] = numerator / denominator\n",
    "    return pred_ratings\n",
    "\n",
    "# 计算 RMSE\n",
    "def compute_rmse(predictions, targets):\n",
    "    mask = targets != 0\n",
    "    mse = torch.mean(((predictions - targets)[mask]) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Calculating user similarity...\")\n",
    "user_similarity = compute_user_similarity(train_ratings_tensor)\n",
    "print(\"User similarity calculated.\")\n",
    "\n",
    "print(\"Predicting ratings...\")\n",
    "pred_ratings = predict(train_ratings_tensor, user_similarity, k=50)\n",
    "print(\"Ratings predicted.\")\n",
    "\n",
    "print(\"Computing RMSE on test set (Collaborative Filtering)...\")\n",
    "rmse_value_cf = compute_rmse(pred_ratings, test_ratings_tensor)\n",
    "print(f\"Test RMSE (Collaborative Filtering): {rmse_value_cf:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time elapsed: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵分解模型（添加偏置项和 Dropout）\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_factors, dropout_rate=0.2):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_factors = torch.nn.Embedding(num_users, num_factors)\n",
    "        self.item_factors = torch.nn.Embedding(num_items, num_factors)\n",
    "        self.user_bias = torch.nn.Embedding(num_users, 1)\n",
    "        self.item_bias = torch.nn.Embedding(num_items, 1)\n",
    "        self.global_bias = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "        torch.nn.init.zeros_(self.user_bias.weight)\n",
    "        torch.nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        user_embedding = self.dropout(self.user_factors(user_idx))\n",
    "        item_embedding = self.dropout(self.item_factors(item_idx))\n",
    "        user_bias = self.user_bias(user_idx).squeeze()\n",
    "        item_bias = self.item_bias(item_idx).squeeze()\n",
    "        return (user_embedding * item_embedding).sum(1) + user_bias + item_bias + self.global_bias\n",
    "\n",
    "# 训练矩阵分解模型\n",
    "def train_matrix_factorization(train_data, num_users, num_items, num_factors=20, lr=0.01, reg=0.001, epochs=50):\n",
    "    model = MatrixFactorization(num_users, num_items, num_factors).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    user_idx = torch.LongTensor(train_data['user_idx'].values).to(device)\n",
    "    item_idx = torch.LongTensor(train_data['movie_idx'].values).to(device)\n",
    "    ratings = torch.FloatTensor(train_data['rating'].values).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    test_rmses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_idx, item_idx)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # 计算测试集上的 RMSE\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_predictions = model(test_user_idx, test_item_idx)\n",
    "            test_rmse = torch.sqrt(torch.nn.functional.mse_loss(test_predictions, test_ratings)).item()\n",
    "            test_rmses.append(test_rmse)\n",
    "        if(epoch % 5 == 0):\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    \n",
    "    # 绘制训练损失和测试集 RMSE\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), test_rmses, label='Test RMSE', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Test RMSE over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 矩阵分解\n",
    "print(\"Training matrix factorization model...\")\n",
    "test_user_idx = torch.LongTensor(test_data['user_idx'].values).to(device)\n",
    "test_item_idx = torch.LongTensor(test_data['movie_idx'].values).to(device)\n",
    "test_ratings = torch.FloatTensor(test_data['rating'].values).to(device)\n",
    "\n",
    "mf_model = train_matrix_factorization(train_data, num_users, num_movies, num_factors=50, lr=0.01, reg=0.01, epochs=50)\n",
    "\n",
    "print(\"Computing RMSE on test set (Matrix Factorization)...\")\n",
    "mf_model.eval()\n",
    "predictions = mf_model(test_user_idx, test_item_idx)\n",
    "mf_rmse = torch.sqrt(torch.nn.functional.mse_loss(predictions, test_ratings)).item()\n",
    "print(f\"Test RMSE (Matrix Factorization): {mf_rmse:.4f}\")\n",
    "\n",
    "# 比较结果\n",
    "print(\"Comparison of Collaborative Filtering and Matrix Factorization:\")\n",
    "print(f\"RMSE (Collaborative Filtering): {rmse_value_cf:.4f}\")\n",
    "print(f\"RMSE (Matrix Factorization): {mf_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数调优\n",
    "def parameter_tuning(train_data, test_user_idx, test_item_idx, test_ratings, num_users, num_movies):\n",
    "    k_values = [20, 50]\n",
    "    lambda_values = [0.001,0.01, 0.1]\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for k in k_values:\n",
    "        for lambda_value in lambda_values:\n",
    "            print(f\"Training with k={k}, lambda={lambda_value}\")\n",
    "            mf_model = train_matrix_factorization(train_data, num_users, num_movies, num_factors=k, lr=0.01, reg=lambda_value, epochs=50)\n",
    "            \n",
    "            mf_model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions = mf_model(test_user_idx, test_item_idx)\n",
    "                mf_rmse = torch.sqrt(torch.nn.functional.mse_loss(predictions, test_ratings)).item()\n",
    "                print(f\"Test RMSE for k={k}, lambda={lambda_value}: {mf_rmse:.4f}\")\n",
    "\n",
    "            if mf_rmse < best_rmse:\n",
    "                best_rmse = mf_rmse\n",
    "                best_params = (k, lambda_value)\n",
    "\n",
    "    print(f\"Best RMSE: {best_rmse:.4f} with k={best_params[0]}, lambda={best_params[1]}\")\n",
    "\n",
    "parameter_tuning(train_data, test_user_idx, test_item_idx, test_ratings, num_users, num_movies)\n",
    "\n",
    "# 比较结果\n",
    "print(\"Comparison of Collaborative Filtering and Matrix Factorization:\")\n",
    "print(f\"RMSE (Collaborative Filtering): {rmse_value_cf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
